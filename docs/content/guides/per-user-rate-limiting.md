---
title: Per-user Rate Limiting
sidebar_position: 2
keywords:
  - guides
  - rate limiting
---

```mdx-code-block
import Zoom from 'react-medium-image-zoom';
import {apertureVersion} from '../apertureVersion.js';
import CodeBlock from '@theme/CodeBlock';
import Tabs from '@theme/Tabs';
import TabItem from "@theme/TabItem";
import {BashTab, TabContent} from './blueprintsComponents.js';
```

## Overview

Rate limiting is a crucial defense against resource abuse. In modern application
environments, where load can fluctuate, rate limiting is essential to manage
situations where user requests exceed the system's capacity,safeguarding against
service overloads and ensuring fairness among users.

Aperture implements this strategy through its high-performance, distributed rate
limiter. This system enforces per-key limits based on fine-grained labels,
thereby offering precise control over API usage. For each unique key, Aperture
maintains a token bucket of a specified bucket capacity and fill rate. The fill
rate dictates the sustained requests per second (RPS) permitted for a key, while
transient overages over the fill rate are accommodated for brief periods, as
determined by the bucket capacity.

<Zoom>

```mermaid
{@include: ./assets/per-user-rate-limiting/rate-limiting.mmd}
```

</Zoom>

The diagram depicts the distribution of tokens across Agents through a global
token bucket. Each incoming request prompts the Agents to decrement tokens from
the bucket. If the bucket has run out of tokens, indicating that the rate limit
has been reached, the incoming request is rejected. Conversely, if tokens are
available in the bucket, the request is accepted. The token bucket is
continually replenished at a predefined fill rate, up to the maximum number of
tokens specified by the bucket capacity.

:::note

The following policy is based on the
[Rate Limiting](/reference/blueprints/rate-limiting/base.md) blueprint.

:::

## Rate Limiting with Aperture SDK

The code below provides a general idea using the Aperture SDK for rate limiting
requests based on business logic.

```mdx-code-block
<Tabs>
<TabItem value="TypeScript">
```

```typescript
import { ApertureClient, Flow, FlowStatusEnum } from "@fluxninja/aperture-js";
import grpc from "@grpc/grpc-js";

// Initialize the Aperture client
const apertureClient = new ApertureClient({
  address: "localhost:8080",
  channelCredentials: grpc.credentials.createSsl(),
});

const labels: Record<string, string> = {
  label_key: "http.request.header.user_id",
  interval: "1s",
};

let flow: Flow | undefined;

if (apertureClient) {
  try {
    // Start the flow to check rate limiting for the incoming request
    flow = await apertureClient.StartFlow(
      "catalog-service.prod.svc.cluster.local",
      {
        labels: labels,
        grpcCallOptions: {
          deadline: Date.now() + 1200000, // 20 minutes deadline
        },
      },
    );

    // Check if the flow is allowed by Aperture
    if (flow.ShouldRun()) {
      // Add business logic to process incoming request
      console.log("Request accepted. Processing...");
    } else {
      console.log("Request rate-limited. Try again later.");
    }
  } catch (e) {
    console.error("Error in flow:", e);
    if (flow) {
      flow.SetStatus(FlowStatusEnum.Error);
    }
  } finally {
    if (flow) {
      flow.End();
    }
  }
}
```

```mdx-code-block
  </TabItem>
</Tabs>
```

## Configuration

This policy is based on the
[Rate Limiting](/reference/blueprints/rate-limiting/base.md) blueprint. It
applies a rate limiter to the **`ingress`** control point on the service
**`catalog-service.prod.svc.cluster.local`** and identifies unique users by
referencing the **`user_id`** header present in the HTTP traffic. Provided by
the Envoy proxy, this header can be located under the label key
**`http.request.header.user_id`** (see [Flow Labels](/concepts/flow-label.md)
for more information).

Each user is allowed **`2`** requests every **`1s`** (1 second) period. A burst
of up to **`40`** requests is allowed. This means that the user can send up to
**`40`** requests in the first second, and then **`2`** requests every second
after that. The bucket gets replenished at the rate of **`2`** requests per
second (the fill rate).

The below `values.yaml` file can be generated by following the steps in the
[Installation](#installation) section.

```mdx-code-block
<Tabs>
<TabItem value="aperturectl values.yaml">
```

```yaml
{@include: ./assets/per-user-rate-limiting/values.yaml}
```

```mdx-code-block
</TabItem>
</Tabs>

```

<details><summary>Generated Policy</summary>
<p>

```yaml
{@include: ./assets/per-user-rate-limiting/policy.yaml}
```

</p>
</details>

:::info

[Circuit Diagram](./assets/per-user-rate-limiting/graph.mmd.svg) for this
policy.

:::

## Installation

Generate a values file specific to the policy. This can be achieved using the
command provided below.

```mdx-code-block
<CodeBlock language="bash">aperturectl blueprints values --name=rate-limiting/base --version={apertureVersion} --output-file=values.yaml</CodeBlock>
```

Apply the policy using the `aperturectl` CLI or `kubectl`.

```mdx-code-block
<Tabs>
  <TabItem value="aperturectl (Aperture Cloud)" label="aperturectl (Aperture Cloud)">
    <TabContent valuesFile="values" tabValue="aperturectl (Aperture Cloud)" />
  </TabItem>
</Tabs>
```

### Policy in Action

When the policy is applied at a service, no more than 2 requests per second
period (after an initial burst of 40 requests) are accepted for a user.

![Static Rate Limiting](./assets/per-user-rate-limiting/dashboard.png)

Ready to use rate limiting within your application? Checkout our
[SDKs](/sdk/sdk.md)
